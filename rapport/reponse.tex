% !TeX spellcheck = fr_CA
\section{Question 1}
On dispose de l'expression de l'opération Softmax tel que:
\begin{equation}	
	y_{w_i}(\overrightarrow{x}) = \frac{e^{a_i}}{\sum_{c=1}^Ke^{a_c}}
\end{equation}
Ainsi que de l'expression de la fonction de perte entropie croisée:
\begin{equation}
\begin{split}
	E_D(W) = - \sum_{n=1}^N \sum_{k=1}^K t_{kn} ln (y_{w_i} (\overrightarrow{x_n}))
\end{split}
\end{equation}

On calcule le gradient de la fonction de perte par rapport à $a_i$ tel que:
\begin{equation}
\begin{split}
	\frac{\partial E_D(W)}{\partial a_i}  &= \frac{\partial}{\partial a_i} \left(-\sum_{n=1}^N \sum_{k=1}^K t_{kn} ln (y_{w_i} (\overrightarrow{x_n})) \right) \\
	&= -\sum_{n=1}^N \sum_{k=1}^K t_{kn} \frac{\partial}{\partial a_i} \left(ln (y_{w_i} (\overrightarrow{x_n})) \right) \\
	&= -\sum_{n=1}^N \sum_{k=1}^K t_{kn} \frac{\partial(ln(y_{w_k}(\overrightarrow{x_n}))}{\partial y_{w_k} \overrightarrow{x_n}} \cdot \frac{\partial y_{w_k} (\overrightarrow{x_n})}{\partial a_i} \\
	\frac{\partial E_D(W)}{\partial a_i}  &= -\sum_{n=1}^N \sum_{k=1}^K t_{kn} \frac{1}{y_{w_k} (\overrightarrow{x_n})} \cdot \frac{\partial y_{w_k} (\overrightarrow{x_n})}{\partial a_i}
\end{split}
\end{equation}

On s'intéresse à la dérivée de l'expression du Softmax:
\begin{equation}
\begin{split}
	\frac{\partial y_{w_i}(\overrightarrow{x})}{\partial a_j} = \frac{\partial}{\partial a_j} \left( \frac{e^{a_i}}{\sum_{c=1}^Ke^{a_c}} \right)
\end{split}
\end{equation}

On note:
\begin{equation}
\begin{split}
	g(a) &= e^{a_i} \\
	h(a) &= \sum_{c=1}^Ke^{a_c}
\end{split}
\end{equation}

La dérivée de 
\begin{equation}
\begin{split}
	\frac{\partial y_{w_i}(\overrightarrow{x})} {\partial a_j} = \frac{g^{'}(a) h(a) - g(a) h^{'}(a)} {(h(a))^2}
\end{split}
\end{equation}

Calcul de $ \frac{\partial g(a)} {\partial a_j} $:
\begin{equation}
\begin{split}
	 \frac{\partial g(a)} {\partial a_j} &= \frac{\partial e^{a_i}} {\partial a_j} \\
	 &= \frac{\partial e^{a_i}} {\partial a_i} \cdot \frac{\partial e^{a_i}} {\partial a_j} \\
	 &= e^{a_i} \cdot \frac{\partial e^{a_i}} {\partial a_j} \\
	 \frac{\partial g(a)} {\partial a_j} &= 
	 \begin{cases}
		 e^{a_i} \text{ si } i=j \\
		 0 \text{ si } i \neq j
	 \end{cases} 
\end{split}
\end{equation}

Calcul de $ \frac{\partial h(a)} {\partial a_j} $:
\begin{equation}
\begin{split}
	\frac{\partial h(a)} {\partial a_j} &= \frac{\partial}{\partial a_j} (\sum_{c=1}^K e^{a_c}) \\
	&= \frac{\partial}{\partial a_j}  \left( \sum_{c=1, c \neq j}^K e^{a_c} + e^{a_j} \right) \\
	&= \frac{\partial}{\partial a_j} \left( \sum_{c=1, c \neq j}^K e^{a_c} + e^{a_j} \right) +  \frac{\partial}{\partial a_j} e^{a_j} \\
	&= 0 + e^{a_j} \\
	\frac{\partial h(a)} {\partial a_j} &=  e^{a_j}
\end{split}
\end{equation}

\section{Question 2}
On dispose des données telles que:
$$ \overrightarrow{x_i} = [i, ii, iii, iv, v] $$
$$ t_i = \{1, 2, 3, 4, 5\} $$ 
où $\overrightarrow{x_i}$ sont les attributs des données d'entraînement $\overrightarrow{x}$, et $t_i$ les différentes valeurs des cibles associées à une donnée $\overrightarrow{x_i}$.

\subsection{Distribution de vraisemblance}
La distribution de vraisemblance se définit telle que: 
$$ P(\overrightarrow{x}, \overrightarrow{t} | \overrightarrow{w}) $$
où $\overrightarrow{x}$ sont les données d'entraînement connus, $\overrightarrow{t}$ sont les cibles connues associés aux données d'entraînement et  $\overrightarrow{w}$ sont les poids du réseau inconnus que le réseau doit déterminer durant la phase d'entraînement. \\
On peut également écrire l'expression telle que:
$$ P((\overrightarrow{x_1}, \overrightarrow{x_2}, ..., \overrightarrow{x_N}), (\overrightarrow{t_1}, \overrightarrow{t_2}, ..., \overrightarrow{t_N}) | \overrightarrow{w_1}, \overrightarrow{w_2}, ..., \overrightarrow{w_N}) $$ 

Afin de déterminer les valeurs des paramètres $\overrightarrow{w}$ du réseau, on peut une méthode d'estimation de maximum de vraisemblance. Les valeurs des paramètres sont trouvées telles que maximisant la probabilité de vraisemblance permettant de produire les données qui sont effectivement observées en entraînement. \\
Cela s'exprime tel que:
$$ \overrightarrow{w} = argmax_{\overrightarrow{w}} P(\overrightarrow{x}, \overrightarrow{t} | \overrightarrow{w}) $$

\subsection{Distribution à priori}
L'expression de la distribution à priori se définit telle que:
$$ P(\overrightarrow{t})  $$
que l'on peut également exprimer tel que:
$$ P(\overrightarrow{t})  = \sum_{\overrightarrow{x}} P(\overrightarrow{x}, \overrightarrow{t}) $$
En applicant la règle du produit des probabilités, on peut écrire:
$$ \sum_{\overrightarrow{x}} P(\overrightarrow{x}, \overrightarrow{t}) =  \sum_{\overrightarrow{x}} P(\overrightarrow{x} | \overrightarrow{t}) \cdot P( \overrightarrow{t})$$
Étant donné que les variables $\overrightarrow{x}$ et $\overrightarrow{t}$ sont des données connues, leur distribution est alors connue. 

\subsection{Hypothèse de distribution gaussienne}
On considère le problème suivant:
$$ P(\overrightarrow{x_i} = v | \overrightarrow{t_i} = 1) $$
\textcolor{red}{TODO}
